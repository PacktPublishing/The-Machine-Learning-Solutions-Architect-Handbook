{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-maryland",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-namibia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "\n",
    "import os \n",
    "\n",
    "import sys \n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "import torch \n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset \n",
    "\n",
    "from transformers import AdamW, BertForSequenceClassification, BertTokenizer \n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder \n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "from types import SimpleNamespace \n",
    "\n",
    "  \n",
    "\n",
    "logger = logging.getLogger(__name__) \n",
    "\n",
    "logger.setLevel(logging.DEBUG) \n",
    "\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout)) \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-hampshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = './data/all-data.csv' \n",
    "\n",
    "data = pd.read_csv(filepath, encoding=\"ISO-8859-1\", \n",
    "\n",
    "    header=None, usecols=[0, 1], \n",
    "\n",
    "    names=[\"sentiment\", \"article\"]) \n",
    "\n",
    "  \n",
    "\n",
    "ord_enc = OrdinalEncoder() \n",
    "\n",
    "data[\"sentiment\"] = ord_enc.fit_transform(data[[\"sentiment\"]]) \n",
    "\n",
    "data = data.astype({'sentiment':'int'}) \n",
    "\n",
    "  \n",
    "\n",
    "train, test = train_test_split(data) \n",
    "\n",
    "train.to_csv(\"./data/train.csv\", index=False) \n",
    "\n",
    "test.to_csv(\"./data/test.csv\", index=False) \n",
    "\n",
    "  \n",
    "\n",
    "MAX_LEN = data.article.str.len().max()  # this is the max length of the sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-layout",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(batch_size, training_dir, filename): \n",
    "\n",
    "    logger.info(\"Get data loader\") \n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True) \n",
    "\n",
    "    dataset = pd.read_csv(os.path.join(training_dir, filename)) \n",
    "\n",
    "    articles = dataset.article.values \n",
    "\n",
    "    sentiments = dataset.sentiment.values \n",
    "\n",
    "  \n",
    "\n",
    "    input_ids = [] \n",
    "\n",
    "    for sent in articles: \n",
    "\n",
    "        encoded_articles = tokenizer.encode(sent, add_special_tokens=True) \n",
    "\n",
    "        input_ids.append(encoded_articles) \n",
    "\n",
    "  \n",
    "\n",
    "    # pad shorter sentences \n",
    "\n",
    "    input_ids_padded = [] \n",
    "\n",
    "    for i in input_ids: \n",
    "\n",
    "        while len(i) < MAX_LEN: \n",
    "\n",
    "            i.append(0) \n",
    "\n",
    "        input_ids_padded.append(i) \n",
    "\n",
    "    input_ids = input_ids_padded \n",
    "\n",
    "  \n",
    "\n",
    "    # mask; 0: added, 1: otherwise \n",
    "\n",
    "    attention_masks = [] \n",
    "\n",
    "    # For each sentence... \n",
    "\n",
    "    for sent in input_ids: \n",
    "\n",
    "        att_mask = [int(token_id > 0) for token_id in sent] \n",
    "\n",
    "        attention_masks.append(att_mask) \n",
    "\n",
    "  \n",
    "\n",
    "    # convert to PyTorch data types. \n",
    "\n",
    "    train_inputs = torch.tensor(input_ids) \n",
    "\n",
    "    train_labels = torch.tensor(sentiments) \n",
    "\n",
    "    train_masks = torch.tensor(attention_masks) \n",
    "\n",
    "    tensor_data = TensorDataset(train_inputs, train_masks, train_labels) \n",
    "\n",
    "    tensor_dataloader = DataLoader(tensor_data, batch_size=batch_size) \n",
    "\n",
    " \n",
    "\n",
    "    return tensor_dataloader \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args): \n",
    "\n",
    "    use_cuda = args.num_gpus > 0 \n",
    "\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\") \n",
    "\n",
    "  \n",
    "\n",
    "    # set the seed for generating random numbers \n",
    "\n",
    "    torch.manual_seed(args.seed) \n",
    "\n",
    "    if use_cuda: \n",
    "\n",
    "        torch.cuda.manual_seed(args.seed) \n",
    "\n",
    "  \n",
    "\n",
    "    train_loader = get_data_loader(args.batch_size, args.data_dir, args.train_file) \n",
    "\n",
    "    test_loader = get_data_loader(args.test_batch_size, args.data_dir, args.test_file) \n",
    "\n",
    "  \n",
    "\n",
    "    model = BertForSequenceClassification.from_pretrained( \n",
    "\n",
    "        \"bert-base-uncased\",   \n",
    "\n",
    "        num_labels=args.num_labels,  \n",
    "\n",
    "        output_attentions=False,   \n",
    "\n",
    "        output_hidden_states=False,  ) \n",
    "\n",
    "  \n",
    "\n",
    "    model = model.to(device) # load the model to the right device \n",
    "\n",
    "     \n",
    "\n",
    "    # configure optimizer \n",
    "\n",
    "    optimizer = AdamW( \n",
    "\n",
    "        model.parameters(), \n",
    "\n",
    "        lr=args.lr,  # learning rate  \n",
    "\n",
    "    ) \n",
    "\n",
    "  \n",
    "\n",
    "    for epoch in range(1, args.epochs + 1): \n",
    "\n",
    "        total_loss = 0 \n",
    "\n",
    "        model.train() \n",
    "\n",
    "        for step, batch in enumerate(train_loader): \n",
    "\n",
    "            b_input_ids = batch[0].to(device) \n",
    "\n",
    "            b_input_mask = batch[1].to(device) \n",
    "\n",
    "            b_labels = batch[2].to(device) \n",
    "\n",
    "            model.zero_grad() \n",
    "\n",
    "  \n",
    "\n",
    "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels) \n",
    "\n",
    "            loss = outputs[0] \n",
    "\n",
    "            total_loss += loss.item() \n",
    "\n",
    "            loss.backward() \n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) \n",
    "\n",
    "            optimizer.step() \n",
    "\n",
    "            if step % args.log_interval == 0: \n",
    "\n",
    "                logger.info( \n",
    "\n",
    "                    \"Train Epoch: {} [{}/{} ({:.0f}%)] Loss: {:.6f}\".format( \n",
    "\n",
    "                        epoch, \n",
    "\n",
    "                        step * len(batch[0]), \n",
    "\n",
    "                        len(train_loader.sampler), \n",
    "\n",
    "                        100.0 * step / len(train_loader), \n",
    "\n",
    "                        loss.item(), \n",
    "\n",
    "                    ) \n",
    "\n",
    "                ) \n",
    "\n",
    "        logger.info(\"Average training loss: %f\\n\", total_loss / len(train_loader))  \n",
    "\n",
    "        test(model, test_loader, device) \n",
    "\n",
    "  \n",
    "\n",
    "    logger.info(\"Saving tuned model.\") \n",
    "\n",
    "    model_2_save = model.module if hasattr(model, \"module\") else model \n",
    "\n",
    "    model_2_save.save_pretrained(save_directory=args.model_dir) \n",
    "\n",
    "     \n",
    "\n",
    "    return model \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-young",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device):     \n",
    "\n",
    "    def get_correct_count(preds, labels): \n",
    "\n",
    "        pred_flat = np.argmax(preds, axis=1).flatten() \n",
    "\n",
    "        labels_flat = labels.flatten() \n",
    "\n",
    "        return np.sum(pred_flat == labels_flat), len(labels_flat) \n",
    "\n",
    "    \n",
    "\n",
    "    model.eval() \n",
    "\n",
    "    _, eval_accuracy = 0, 0 \n",
    "\n",
    "    total_correct = 0 \n",
    "\n",
    "    total_count = 0 \n",
    "\n",
    " \n",
    "\n",
    "    with torch.no_grad(): \n",
    "\n",
    "        for batch in test_loader: \n",
    "\n",
    "            b_input_ids = batch[0].to(device) \n",
    "\n",
    "            b_input_mask = batch[1].to(device) \n",
    "\n",
    "            b_labels = batch[2].to(device) \n",
    "\n",
    "  \n",
    "\n",
    "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask) \n",
    "\n",
    "            preds = outputs[0] \n",
    "\n",
    "            preds = preds.detach().cpu().numpy() \n",
    "\n",
    "            label_ids = b_labels.to(\"cpu\").numpy() \n",
    "\n",
    "                         \n",
    "\n",
    "            num_correct, num_count = get_correct_count(preds, label_ids) \n",
    "\n",
    "            total_correct += num_correct \n",
    "\n",
    "            total_count += num_count \n",
    "\n",
    "             \n",
    "\n",
    "    logger.info(\"Test set: Accuracy: %f\\n\", total_correct/total_count) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = SimpleNamespace(num_labels=3, batch_size=16, test_batch_size=10, epochs=3, lr=2e-5, seed=1,log_interval =50, model_dir = \"model/\", data_dir=\"data/\", num_gpus=1, train_file = \"train.csv\", test_file=\"test.csv\")      \n",
    "\n",
    "model = train(args) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-occurrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(request_body, request_content_type): \n",
    "\n",
    "    if request_content_type == \"application/json\": \n",
    "\n",
    "        data = json.loads(request_body)     \n",
    "\n",
    "        if isinstance(data, str): \n",
    "\n",
    "            data = [data] \n",
    "\n",
    "        elif isinstance(data, list) and len(data) > 0 and isinstance(data[0], str): \n",
    "\n",
    "            pass \n",
    "\n",
    "        else: \n",
    "\n",
    "            raise ValueError(\"Unsupported input type. Input type can be a string or an non-empty list. \\ \n",
    "\n",
    "                             I got {}\".format(data)) \n",
    "\n",
    "                        \n",
    "\n",
    "        tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True) \n",
    "\n",
    "         \n",
    "\n",
    "        input_ids = [tokenizer.encode(x, add_special_tokens=True) for x in data] \n",
    "\n",
    "         \n",
    "\n",
    "        # pad shorter sentence \n",
    "\n",
    "        padded =  torch.zeros(len(input_ids), MAX_LEN)  \n",
    "\n",
    "        for i, p in enumerate(input_ids): \n",
    "\n",
    "            padded[i, :len(p)] = torch.tensor(p) \n",
    "\n",
    "      \n",
    "\n",
    "        # create mask \n",
    "\n",
    "        mask = (padded != 0) \n",
    "\n",
    "         \n",
    "\n",
    "        return padded.long(), mask.long() \n",
    "\n",
    "    raise ValueError(\"Unsupported content type: {}\".format(request_content_type)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-chemistry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(input_data, model): \n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "    model.to(device) \n",
    "\n",
    "    model.eval() \n",
    "\n",
    "  \n",
    "\n",
    "    input_id, input_mask = input_data \n",
    "\n",
    "    input_id = input_id.to(device) \n",
    "\n",
    "    input_mask = input_mask.to(device) \n",
    "\n",
    "    with torch.no_grad(): \n",
    "\n",
    "        y = model(input_id, attention_mask=input_mask)[0] \n",
    "\n",
    "    return y \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-count",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"Operating profit outpaced the industry average\" \n",
    "\n",
    "request_body = json.dumps(article) \n",
    "\n",
    "enc_data, mask = input_fn(request_body, 'application/json') \n",
    "\n",
    "output = predict_fn((enc_data, mask), model) \n",
    "\n",
    "preds = output.detach().cpu().numpy() \n",
    "\n",
    "print(\"sentiment label : \" + str(np.argmax(preds))) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
