{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "polar-order",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opacus\n",
      "  Downloading opacus-0.14.0-py3-none-any.whl (114 kB)\n",
      "\u001b[K     |████████████████████████████████| 114 kB 735 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.9/site-packages (from opacus) (1.19.5)\n",
      "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.9/site-packages (from opacus) (1.8.1)\n",
      "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.9/site-packages (from opacus) (1.6.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from torch>=1.3->opacus) (3.7.4.3)\n",
      "Installing collected packages: opacus\n",
      "Successfully installed opacus-0.14.0\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.3 is available.\n",
      "You should consider upgrading via the '/usr/local/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install opacus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "distinguished-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.metrics import accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "phantom-white",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "major-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChurnDataset(Dataset):\n",
    " \n",
    "    def __init__(self, csv_file):\n",
    "  \n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        df = df.drop([\"Surname\", \"CustomerId\", \"RowNumber\"], axis=1)\n",
    "\n",
    "        # Grouping variable names\n",
    "        self.categorical = [\"Geography\", \"Gender\"]\n",
    "        self.target = \"Exited\"\n",
    "\n",
    "        # One-hot encoding of categorical variables\n",
    "        self.churn_frame = pd.get_dummies(df, prefix=self.categorical)\n",
    "\n",
    "        # Save target and predictors\n",
    "        self.X = self.churn_frame.drop(self.target, axis=1)\n",
    "        self.y = self.churn_frame[\"Exited\"]\n",
    "        \n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_array  = scaler.fit_transform(self.X)\n",
    "        self.X = pd.DataFrame(X_array)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.churn_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Convert idx from tensor to list due to pandas bug (that arises when using pytorch's random_split)\n",
    "        if isinstance(idx, torch.Tensor):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        return [self.X.iloc[idx].values, self.y[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "naval-envelope",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CHURN_model():\n",
    "    model = nn.Sequential(nn.Linear(13, 64), \n",
    "                    nn.ReLU(), \n",
    "                    nn.Linear(64, 64), \n",
    "                    nn.ReLU(), \n",
    "                    nn.Linear(64, 1)) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "unique-australia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(csv_file, batch_size):\n",
    "     # Load dataset\n",
    "    dataset = ChurnDataset(csv_file)\n",
    "\n",
    "    # Split into training and test\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    trainset, testset = random_split(dataset, [train_size, test_size])\n",
    "    \n",
    "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    testloader = DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    return trainloader, testloader, trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "monetary-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainloader, net, optimizer, n_epochs=100):\n",
    "     \n",
    "    device = \"cpu\"\n",
    "\n",
    "    # Define the model\n",
    "    #net = get_CHURN_model()\n",
    "    net = net.to(device)\n",
    "    \n",
    "    #criterion = nn.CrossEntropyLoss() \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "    # Train the net\n",
    "    loss_per_iter = []\n",
    "    loss_per_batch = []\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward + backward + optimize\n",
    "            outputs = net(inputs.float())\n",
    "            loss = criterion(outputs, labels.float().unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Save loss to plot\n",
    "            running_loss += loss.item()\n",
    "            loss_per_iter.append(loss.item())\n",
    "\n",
    "        \n",
    "        print(\"Epoch {} - Training loss: {}\".format(epoch, running_loss/len(trainloader))) \n",
    "        \n",
    "        running_loss = 0.0\n",
    "        \n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "august-saturday",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"data/churn.csv\"\n",
    "\n",
    "trainloader, testloader, train_ds, test_ds = get_dataloader(csv_file, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "regional-arbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Training loss: 0.42998170768842103\n",
      "Epoch 1 - Training loss: 0.3585398425348103\n",
      "Epoch 2 - Training loss: 0.34484875975176693\n",
      "Epoch 3 - Training loss: 0.33772834809497\n",
      "Epoch 4 - Training loss: 0.3370456677861512\n",
      "Epoch 5 - Training loss: 0.3331598186865449\n",
      "Epoch 6 - Training loss: 0.32938209315761924\n",
      "Epoch 7 - Training loss: 0.3280104883015156\n",
      "Epoch 8 - Training loss: 0.3263300991617143\n",
      "Epoch 9 - Training loss: 0.3237824782729149\n",
      "Epoch 10 - Training loss: 0.3222683455329388\n",
      "Epoch 11 - Training loss: 0.32311330642551184\n",
      "Epoch 12 - Training loss: 0.3190927365794778\n",
      "Epoch 13 - Training loss: 0.31648382991552354\n",
      "Epoch 14 - Training loss: 0.3140755801461637\n",
      "Epoch 15 - Training loss: 0.3146016987040639\n",
      "Epoch 16 - Training loss: 0.3130694762803614\n",
      "Epoch 17 - Training loss: 0.31548011796548964\n",
      "Epoch 18 - Training loss: 0.3086287043057382\n",
      "Epoch 19 - Training loss: 0.3070000804029405\n",
      "Epoch 20 - Training loss: 0.30901680393144487\n",
      "Epoch 21 - Training loss: 0.3056166450958699\n",
      "Epoch 22 - Training loss: 0.30514283911325035\n",
      "Epoch 23 - Training loss: 0.30451963939704\n",
      "Epoch 24 - Training loss: 0.3013359002768993\n",
      "Epoch 25 - Training loss: 0.30146524431183935\n",
      "Epoch 26 - Training loss: 0.2981513495091349\n",
      "Epoch 27 - Training loss: 0.29951553759165106\n",
      "Epoch 28 - Training loss: 0.29659967217594385\n",
      "Epoch 29 - Training loss: 0.29601812325418\n",
      "Epoch 30 - Training loss: 0.2928078792989254\n",
      "Epoch 31 - Training loss: 0.2925607037730515\n",
      "Epoch 32 - Training loss: 0.29099605083465574\n",
      "Epoch 33 - Training loss: 0.2875820199027658\n",
      "Epoch 34 - Training loss: 0.28796007549390196\n",
      "Epoch 35 - Training loss: 0.2862978338263929\n",
      "Epoch 36 - Training loss: 0.2849194521084428\n",
      "Epoch 37 - Training loss: 0.2819406180642545\n",
      "Epoch 38 - Training loss: 0.28039060058072207\n",
      "Epoch 39 - Training loss: 0.28055999856442215\n",
      "Epoch 40 - Training loss: 0.27712538102641704\n",
      "Epoch 41 - Training loss: 0.2762277826666832\n",
      "Epoch 42 - Training loss: 0.2775536535307765\n",
      "Epoch 43 - Training loss: 0.2720752076245844\n",
      "Epoch 44 - Training loss: 0.274109112424776\n",
      "Epoch 45 - Training loss: 0.2703379719983786\n",
      "Epoch 46 - Training loss: 0.27107494017109274\n",
      "Epoch 47 - Training loss: 0.2681888356804848\n",
      "Epoch 48 - Training loss: 0.26730580190196634\n",
      "Epoch 49 - Training loss: 0.26655641878023745\n"
     ]
    }
   ],
   "source": [
    "net = get_CHURN_model()\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), weight_decay=0.0001, lr=0.003)\n",
    "\n",
    "model = train(trainloader, net, optimizer, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-requirement",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
